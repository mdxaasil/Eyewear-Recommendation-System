{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 12:30:36.390753: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-10 12:30:36.600085: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-10 12:30:37.704673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn import neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the path to your image file with the appropriate extension (e.g., .jpg, .png)\n",
    "image_path=r\"FaceShape_Dataset/heart (1000).jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 12:33:53.760501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-12-10 12:33:53.863721: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-10 12:33:53.863975: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-10 12:33:53.863985: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-12-10 12:33:53.864161: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-10 12:33:53.864196: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-12-10 12:33:53.943174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 682ms/step\n",
      "Class: Heart\n",
      "Confidence Score: 0.9843203\n"
     ]
    }
   ],
   "source": [
    "# Disable scientific notation for clarity \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "  \n",
    "# Load the model TEAM09/\n",
    "model = load_model(\"converted_keras/keras_model.h5\", compile=False)\n",
    "\n",
    "# Load the labels\n",
    "with open(\"converted_keras/labels.txt\", \"r\") as file:\n",
    "    class_names = file.readlines()\n",
    "\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1\n",
    "\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "\n",
    "# turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# Predicts the model\n",
    "prediction = model.predict(data)\n",
    "index = np.argmax(prediction)\n",
    "class_name = class_names[index]\n",
    "confidence_score = prediction[0][index]\n",
    "\n",
    "# Print prediction and confidence score\n",
    "print(\"Class:\", class_name[2:], end=\"\")\n",
    "print(\"Confidence Score:\", confidence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lisaa/mainpy/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.3.2 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "knn_model_file = \"KNN/knn_best_model.pkl\"\n",
    "best_model = joblib.load(knn_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmark_features(image_path):\n",
    "    global noisy_datapoints\n",
    "\n",
    "    landmark_features = []\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (500, 500))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    if len(faces) != 1:\n",
    "        noisy_datapoints += 1\n",
    "        return None\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        for n in range(0, 68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "\n",
    "            cv2.circle(gray, (x, y), 2, (0, 255, 0), -1)\n",
    "            landmark_features.append((x, y))\n",
    "\n",
    "    return landmark_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"yes\")\n",
    "# x_image_paths = []\n",
    "# print(\"1\")\n",
    "# test_path = \"KNN/FaceShape_testing\"\n",
    "# print(\"2\")\n",
    "# for root, dirs, files in os.walk(test_path):\n",
    "#     print(\"3\")\n",
    "#     for file in files:\n",
    "#         print(file)\n",
    "#         if file.endswith(\".jpg\") or file.endswith(\".jpeg\"):\n",
    "#             label = file.split(\" \")[0]\n",
    "#             x_image_paths.append(os.path.join(root, file))\n",
    "# x_predict = []\n",
    "# y_labels = []\n",
    "# for path in x_image_paths:\n",
    "#     facepoints = extract_landmark_features(path)\n",
    "#     if facepoints is None:\n",
    "#         continue\n",
    "#     x_predict.append(facepoints)\n",
    "#     y_labels.append(path.split(\"\\\\\")[1].split(\".\")[0])\n",
    "\n",
    "# x_predict = np.array(x_predict)\n",
    "# n_samples, n_landmarks, n_coordinates = x_predict.shape\n",
    "# x_predict = x_predict.reshape(n_samples, n_landmarks * n_coordinates)\n",
    "\n",
    "# x_predict = np.array(x_predict)\n",
    "# y_predicted = best_model.predict(x_predict)\n",
    "# y_predicted_proba = best_model.predict_proba(x_predict)\n",
    "\n",
    "# for label, predict, prob in zip(y_labels, y_predicted, y_predicted_proba):\n",
    "#     print(f\"{label}: {predict} (Confidence: {prob.max():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered\n",
      "FaceShape_Dataset/heart (1000).jpg\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"entered\")\n",
    "x_predict = []\n",
    "print(image_path)\n",
    "image=cv2.imread(image_path)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "facepoints = extract_landmark_features(image_path)\n",
    "# if facepoints is None:\n",
    "#     print(\"None\")\n",
    "# x_predict.append(facepoints)\n",
    "\n",
    "# x_predict = np.array(x_predict)\n",
    "# n_samples, n_landmarks, n_coordinates = x_predict.shape\n",
    "# x_predict = x_predict.reshape(n_samples, n_landmarks * n_coordinates)\n",
    "# x_predict = np.array(x_predict)\n",
    "# y_predicted = best_model.predict(x_predict)\n",
    "# y_predicted_proba = best_model.predict_proba(x_predict)\n",
    "\n",
    "# print(y_predicted)\n",
    "# print(y_predicted_proba)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
